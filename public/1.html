<!DOCTYPE html>
<html>
<body>
<audio id='music' ref="audio" src="http://127.0.0.1/uploadfile/music/夜空中最亮的星.mp3" autoplay></audio>
<canvas id="audioCanvas" width="400" height="200" style="border:1px solid #000000;"></canvas>
 
<script>
// 获取Canvas元素
var canvas = document.getElementById('audioCanvas');
var ctx = canvas.getContext('2d');
 
// 创建一个AudioContext
var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
 
// 创建一个MediaElementSource来从音频元素获取音频数据
// 这里假设你有一个<audio>元素，可以直接引用，或者使用其他输入源

var audio = document.getElementById('music')
var source = audioCtx.createMediaElementSource(audio);
 
// 创建一个分析器
var analyser = audioCtx.createAnalyser();
source.connect(analyser);
analyser.connect(audioCtx.destination);
 
// 获取音频文件并设置来源
// 这里假设你已经有了一个音频文件的URL
// var audio = new Audio('./ThatGirl.mp3');
// audio.crossOrigin = 'anonymous'; // 如果音频文件跨域，需要设置这个属性
// audio.play(); // 播放音频
 
// 将音频源连接到分析器
source.mediaElement = audio;
 
function renderFrame() {
  // 清除Canvas
  ctx.clearRect(0, 0, canvas.width, canvas.height);
 
  // 设置分析器的FFT大小以及频率范围
  analyser.fftSize = 256;
  var bufferLength = analyser.frequencyBinCount;
  var dataArray = new Uint8Array(bufferLength);
 
  // 获取当前频率数据
  analyser.getByteTimeDomainData(dataArray);
 
  // 绘制Canvas
  ctx.fillStyle = 'rgb(200, 200, 200)';
  ctx.fillRect(0, 0, canvas.width, canvas.height);
  ctx.lineWidth = 2;
  ctx.strokeStyle = 'rgb(0, 0, 0)';
 
  ctx.beginPath();
  var sliceWidth = canvas.width * 1.0 / bufferLength;
  var x = 0;
 
  for(var i = 0; i < bufferLength; i++) {
    var v = dataArray[i] / 128.0;
    var y = v * canvas.height/2;
 
    if(i === 0) {
      ctx.moveTo(x, y);
    } else {
      ctx.lineTo(x, y);
    }
 
    x += sliceWidth;
  }
 console.log(x);
  ctx.lineTo(canvas.width, canvas.height/2);
  ctx.stroke();
 
  // 递归调用以持续更新Canvas
  window.requestAnimationFrame(renderFrame);
}
 
// 开始渲染
renderFrame();
</script>
 
</body>
</html>